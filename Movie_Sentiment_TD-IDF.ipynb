{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Review Sentiment Analysis Using TF-IDF\n",
    "We use term frequency-inverse document frequency (TF-IDF) to weigh words and build a vocabulary for use as a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from time import time\n",
    "# Use scikit-learn to do the vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# SVM as the classifier\n",
    "from sklearn import svm\n",
    "# Just for reporting purposes\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Folder with movie review files\n",
    "data_dir = \"/Users/<>/Documents/Data/review_polarity/txt_sentoken\"\n",
    "# Class names for classification\n",
    "classes = ['pos', 'neg']\n",
    "\n",
    "# Read the data from the path\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "for curr_class in classes:\n",
    "    dirname = os.path.join(data_dir, curr_class)\n",
    "    for fname in os.listdir(dirname):\n",
    "        with open(os.path.join(dirname, fname), 'r') as f:\n",
    "            content = f.read()\n",
    "            # File names are of the form cvxxx_xxxxx.txt\n",
    "            # Use files that start with the cv9xx_xxxxx.txt for test\n",
    "            if fname.startswith('cv9'):\n",
    "                test_data.append(content)\n",
    "                test_labels.append(curr_class)\n",
    "            else:\n",
    "                train_data.append(content)\n",
    "                train_labels.append(curr_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "# of train data samples:\t1800\n",
      "# of test  data samples:\t200\n",
      "************************************************************\n",
      "Train review: [in recent years , harrison ford has been such a grave screen presence , scowling through the likes o] with sentiment: [pos]\n",
      "Test review: [the most interesting part of \" can't hardly wait \" just happens to be not only the most human , but ] with sentiment: [neg]\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many samples are available and view some data\n",
    "print(\"**\" * 30)\n",
    "print(\"# of train data samples:\\t%d\\n# of test  data samples:\\t%d\" % \n",
    "      (len(train_data), len(test_data)))\n",
    "print(\"**\" * 30)\n",
    "\n",
    "idx = 150 # Some random index between 0, 199\n",
    "print(\"Train review: [%s] with sentiment: [%s]\" % (train_data[idx][:100], train_labels[idx]))\n",
    "print(\"Test review: [%s] with sentiment: [%s]\" % (test_data[idx][:100], test_labels[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build vocabulary and vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=5,      # Ignore terms that have a document frequency strictly lower than the given threshold\n",
    "                             max_df = 0.8,  # Ignore terms that have a document frequency strictly higher than the given threshold\n",
    "                             sublinear_tf=True, \n",
    "                             use_idf=True)  # Enable inverse-document-frequency reweighting\n",
    "\n",
    "# Learn vocabulary and idf, return term-document matrix\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "test_vectors = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 12495\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary length: %d\" % len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a linear SVM classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform classification with SVM with a linear kernel\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "t0 = time()\n",
    "classifier.fit(train_vectors, train_labels)\n",
    "t1 = time()\n",
    "prediction = classifier.predict(test_vectors)\n",
    "t2 = time()\n",
    "time_train = t1 - t0\n",
    "time_predict = t2 - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Results\n",
      "Training time: 7.215s; Prediction time: 0.679s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.91      0.92      0.92       100\n",
      "        pos       0.92      0.91      0.91       100\n",
      "\n",
      "avg / total       0.92      0.92      0.91       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification results as a report\n",
    "print(\"Classification Results\")\n",
    "print(\"Training time: %.3fs; Prediction time: %.3fs\" % (time_train, time_predict))\n",
    "print(classification_report(test_labels, prediction))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
